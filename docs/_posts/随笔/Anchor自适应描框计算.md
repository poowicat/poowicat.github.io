---
title: Anchor自适应描框计算
date: 2022-05-23 14:08:21
permalink: /pages/d45e4b/
sidebar: auto
categories:
  - 随笔
tags:
  - 
author: 
  name: poowicat
  link: https://github.com/poowicat
---
# 自适应锚框计算

##### 原理：

- 一个**Anchor Box**相当于一系列预设边框生成规则

- 根据Anchor Box 可以在图像的任意位置，生成一系列边框

- **Faster R-CNN**进行**Anchor Box**生成的**Feature Map**是原图下采样16倍得到的，这样不同的长宽比实际上是将面积为16×16的区域，拉伸为不同的形状，具体做法：将也就是说只是中心点一样，面积一样，形状发生了改变

  ![image](C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.69st6jt0yvc0.webp)
  
  <!-- more -->

##### 优点：

- 框住目标几率变大，大大提高了检测的召回率

##### 边框计算：

![image](C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.4unj7pre38q0.webp)

##### Yolo算法中：

- 针对不同的数据集，都会有初始设定长宽的描框。

  ![image](C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.63q4e6oysd80.webp)

- 在网络训练中，网络在初始描框的基础上输出预测框，进而和真实框**groundtruth**进行对比，计算误差，再反向更新，**迭代网络参数**

- yolov3、yolov4中，训练时，计算初始描框值是通过单独的程序运行的

- 而**YOLOv5**中，将此功能嵌入代码中，每次训练中，都会自适应不同训练集中的最佳描框值

- 如果觉得描框效果不好，也可以在代码中将此功能**关闭**



##### 为什么需要Anchor Box？

###### 前言

在了解anchor box之前，需要先了解一些目标识别的方法

###### 1、滑动窗口

- 原始目标检测方法

- 固定尺寸窗口

- 根据设定步伐，一步一步从左至右从上至下。把每个窗口输入到卷积神经网络中，进行预测和分类

  ###### 缺点：

  1. 由于尺寸固定，不适合形变较大的物体
  2. 窗口较多，运算巨大

###### 2、区域建议

![image](C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.1prmn1btb8g0.webp)

1. 以上为R-CNN系列的核心思想
2. 以Faster为例，模型中使用了两个神经网络，**一个是CNN。一个是RPN**，区域建议网络**不负责**图像的**分类**，它只负责选取图像中可能属于数据集其中一类的候选区域也就是检测
3. 接下来就是把RPN产生的候选区域输入到分类网络中进行最终的分类

###### 3、anchor box

- 第一次这个提出在 Faster R-CNN论文里面；

- 要理解它首先得理解一下两个问题：

  1. ###### 为什么要提出anchor box？

     主要两个原因：

     - 一个窗口只能检测一个目标
     - 无法解决多尺度问题

  2. ###### 为什么使用不同尺寸和不同长宽比？

     ![image](C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.5irseyk0y840.webp)

     ![image](C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.5o65ntd59o40.webp)

     - 如上图所示，红色框为feature map映射的anchor box，而黄框分别为，行人和车辆的 **真实标签** 。这样的话通过叫交并比就很难获取feature map中每个单元对应的标签
     - 可以用，Box1与行人的IOU比较大，可用于训练和预测行人
     - Box2与车辆的IOU比较大，可以用于训练和预测汽车
     - 使用不同长宽比和尺寸的anchor box **这样更加有针对性！**

  3. ###### anchor box 的尺寸如何选择？

     目前主要有是3种方式：

     - 人为经验选取
     - k-means聚类
     - 作为超参数学习



##### anchor box用在哪个阶段？

- 既用于训练也用于预测阶段；
- 如何使用的：

###### 1、训练阶段

- 在实际预测会生成多个描框

- 然后通过迭代将我们的损失降到最小，让预测的框与之前输入的描框尽可能一致

  ###### 标注

  1. 训练阶段，需要把anchor box作为标注样本
  2. 为了训练样本，需要为每个描框标注两类标签：1、类别；2、偏移量（offset）

  ###### 标注

  1. 首先生成多个描框
  2. 预测每个描框**类别**和**偏移量**
  3. 根据偏移量调整描框位置，从而得到预测边框
  4. 最后筛选需要输出的预测边界框

  ###### 训练

###### 2、预测阶段

1. 生成多个anchor box，根据训练模型参数预测这些anchor box的类别和偏移量
2. 得出预测边界框
3. 由于阈值和anchor box数量选择的问题，同一个目标可能会输出多个相似的预测边界框，**缺点**：这样不仅不简洁，还会增加计算量。
4. **解决：**使用非极大值抑制（NMS)
   1. NMS就是一个**抑制冗余**的**反复迭代**-遍历的过程。
   2. 对于预测边界框，模型最终会计算它属于每个类别的概率值
   3. 其中最大对应的类别就是预测边框的类别；
   4. 同一幅图片--->所有预测边界框**降序**排列（不分类别）--->去除最大 **概率**的预测边界框（**基准**）---> 计算剩余预测边框与基准的**IOU**---->如果大于给定某个阈值---->则移除此边界框
   5. 以上做法，保留了概率最大的预测边界框，并移除了其他与其相似的边界框
   6. 接下来，从剩余中选出概率值最大的预测边界框----->并计算过程**重复上述过程**。



