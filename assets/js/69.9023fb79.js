(window.webpackJsonp=window.webpackJsonp||[]).push([[69],{558:function(i,e,t){"use strict";t.r(e);var l=t(21),v=Object(l.a)({},(function(){var i=this,e=i.$createElement,t=i._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":i.$parent.slotKey}},[t("h3",{attrs:{id:"简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[i._v("#")]),i._v(" 简介：")]),i._v(" "),t("p",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/%E5%8D%B7%E7%A7%AF%E6%A0%B8.yeoypfv5neo-165277311790624.gif",alt:"卷积核"}})]),i._v(" "),t("ul",[t("li",[i._v("卷积使用kernel从输入图像提取特征")]),i._v(" "),t("li",[i._v("kernel是矩阵")]),i._v(" "),t("li",[i._v("可在图像时滑动并输入相乘")]),i._v(" "),t("li",[i._v("以某种我们期望的方式 "),t("strong",[i._v("增强")]),i._v("输出")]),i._v(" "),t("li",[i._v("上面的kernel可用于锐化图像。")]),i._v(" "),t("li",[i._v("如下图：中心值为3 * 5 + 2 * -1 + 2 * -1 + 2 * -1 + 2 * -1 =7，值3增加到7。第二个图像，输出是1 * 5 + 2 * -1 + 2 * -1 + 2 * -1 + 2 * -1 = -3，值1减少到-3。显然，3和1之间的对比度增加到了7和-3，图像将更清晰锐利：")]),i._v(" "),t("li",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.4da6sqanyjs0-165277315021628.webp",alt:"image"}})]),i._v(" "),t("li",[i._v("通过深层CNN，我们无需再手工设计kernel来提取特征，而是可以直接学习这些可提取潜在特征的kernel值")])]),i._v(" "),t("h3",{attrs:{id:"kernel与fliter"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kernel与fliter"}},[i._v("#")]),i._v(" Kernel与Fliter")]),i._v(" "),t("ol",[t("li",[i._v("区分kernel和Fliter\n"),t("ul",[t("li",[i._v("kernel是权重 矩阵，将权重矩阵与输入相乘提取相关特征，卷积名称就是kernel矩阵的 "),t("strong",[i._v("维数")])]),i._v(" "),t("li",[i._v("filter与kernel串联，每个kernel分配给输入的特定通道，")]),i._v(" "),t("li",[i._v("filter总比kernel大一维")]),i._v(" "),t("li",[i._v("例如：在2D卷积中，filter是3D矩阵（本质上是2D（即kernel）的串联）")]),i._v(" "),t("li",[i._v("具有kernel尺寸h*w和输入通道k的cnn层，filter尺寸为K * H * w")]),i._v(" "),t("li",[i._v("普通的卷积层实际上由多个这样的filter组成。"),t("em",[i._v("为了简化下面的讨论，除非另有说明，否则假定仅存在一个filter，因为所有filter都会重复相同的操作。")])])])])]),i._v(" "),t("h3",{attrs:{id:"_1d-2d-3d卷积"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1d-2d-3d卷积"}},[i._v("#")]),i._v(" 1D,2D,3D卷积")]),i._v(" "),t("ul",[t("li",[i._v("一维卷积通常用于时间序列数据分析；")]),i._v(" "),t("li",[i._v("一维数据输入可具有多个通道")]),i._v(" "),t("li",[i._v("滤波器只能沿一个方向移动，因此输出为1D")]),i._v(" "),t("li",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.7cgsnwzqwuo0-165277319168930.webp",alt:"image"}})]),i._v(" "),t("li",[i._v("在下图中，kernel尺寸为3 * 3，并且filter中有多个这样的kernel（标记为黄色）。这是因为输入中有多个通道（标记为蓝色），并且我们有一个kernel对应于输入中的每个通道。显然，这里的filter可以在两个方向上移动，因此最终输出是2D。2D卷积是最常见的卷积，在计算机视觉中大量使用。")]),i._v(" "),t("li",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.13qw85n9j128.webp",alt:"image"}})]),i._v(" "),t("li",[i._v("很难可视化3D filter（因为它是4D矩阵)，因此我们在这里只讨论单通道3D卷积。如下图所示，在3D卷积中，kernel可以在3个方向上移动，因此获得的输出也是3D。")]),i._v(" "),t("li",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.1v8y85yhijhc-165277320766033.webp",alt:"image"}})])]),i._v(" "),t("h2",{attrs:{id:"转置-transposed-卷积"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#转置-transposed-卷积"}},[i._v("#")]),i._v(" "),t("strong",[i._v("转置(Transposed)卷积")])]),i._v(" "),t("ul",[t("li",[i._v("下图gif展示2D卷积如何减小输入尺寸")]),i._v(" "),t("li",[i._v("但有时我们需要对输入进行上采样等处理")]),i._v(" "),t("li",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/2.6y9dgyeb4e00-165277321587235.gif",alt:"2"}})]),i._v(" "),t("li",[i._v("为了使卷积实现此目标，使用转置卷积或反卷积（他并不是真正的逆转卷积运算）的卷积修改版，下面gif的虚线框表示padding")]),i._v(" "),t("li",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/3.5wbz23uchgg0-165277322511937.gif",alt:"3"}})]),i._v(" "),t("li",[i._v("这些动画很直观的展示了如何基于不同的padding模式从同一输入产生不同的"),t("strong",[i._v("上采样")]),i._v("输出。这种卷积在现代CNN网络中非常常用，主要是因为它们具有"),t("strong",[i._v("增加图像尺寸的能力。")])]),i._v(" "),t("li",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/4.6inm64wlsl4-165277323320039.webp",alt:"4"}})])]),i._v(" "),t("h4",{attrs:{id:"可分离卷积"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可分离卷积"}},[i._v("#")]),i._v(" 可分离卷积")]),i._v(" "),t("ul",[t("li",[t("p",[i._v("指卷积kernel分解为低维度、kernel")])]),i._v(" "),t("li",[t("p",[i._v("可分离卷积有两种主要类型，")])]),i._v(" "),t("li",[t("p",[i._v("1、空间上可分离卷积")])]),i._v(" "),t("li",[t("blockquote",[t("p",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.327iw7tiigc0-165277323995541.webp",alt:"image"}})])])]),i._v(" "),t("li",[t("p",[i._v("2、深度可分离卷积（广泛应用于轻量级CNN模型中。并提供了非常好的性能，")])]),i._v(" "),t("li",[t("p",[i._v("具有2个输入通道的128个filter的标准2D卷积")])]),i._v(" "),t("li",[t("p",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.3k5clxuizlo0-165277324757243.webp",alt:"image"}})])]),i._v(" "),t("li",[t("p",[i._v("深度可分离的2D卷积，它首先分别处理每个通道，然后进行通道间卷积")])]),i._v(" "),t("li",[t("p",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.3r6ehyuwnv00-165277325378945.webp",alt:"image"}})])]),i._v(" "),t("li",[t("p",[i._v("用可分离卷积原因："),t("strong",[i._v("效率！！！")])]),i._v(" "),t("ul",[t("li",[i._v("可显著减少所需参数量")])])])]),i._v(" "),t("h3",{attrs:{id:"扩张-空洞-dilated-atrous-卷积"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩张-空洞-dilated-atrous-卷积"}},[i._v("#")]),i._v(" 扩张/空洞（Dilated/Atrous）卷积")]),i._v(" "),t("ul",[t("li",[i._v("所有卷积层，他们都是一起处理所有相邻值")]),i._v(" "),t("li",[i._v("但是有时跳过某些输入值可能会更好")]),i._v(" "),t("li",[i._v("这就是为什么引入扩张卷积的原因（也称空洞卷积）")]),i._v(" "),t("li",[i._v("它的修改允许kernel在不增加参数数量下增加其"),t("strong",[i._v("感受野")])]),i._v(" "),t("li",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/poowicat/pic_store@main/blog/5.4cv0ww2bwxi0.gif",alt:"image"}})]),i._v(" "),t("li",[i._v("上图可视，kernel可以使用与之前相同的9个参数，来构造更广阔的领域")]),i._v(" "),t("li",[i._v("但会导致信息丢失")]),i._v(" "),t("li",[i._v("但是某些应用中，总体效果是正面的")])]),i._v(" "),t("h3",{attrs:{id:"可变形卷积"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可变形卷积"}},[i._v("#")]),i._v(" 可变形卷积")]),i._v(" "),t("ul",[t("li",[t("p",[i._v("kernel形状仅为正方形/矩形（或其他一些需要手动确定的形状）")])]),i._v(" "),t("li",[t("p",[i._v("因此它们只能在这种模式下使用，如果卷积形状本身可学习呢？")])]),i._v(" "),t("li",[t("p",[i._v("这是引入可变形卷积背后的思想")])]),i._v(" "),t("li",[t("p",[t("img",{attrs:{src:"C:/Users/ziyih/Documents/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87/image.3dff9ro5wzg0-165277328259948.webp",alt:"image"}})])]),i._v(" "),t("li",[t("p",[i._v("实现：")]),i._v(" "),t("ul",[t("li",[i._v("每个kernel都用两个不同的矩阵表示")]),i._v(" "),t("li",[i._v("第一分支，从原点 "),t("strong",[i._v("预测")]),i._v(" 偏移")]),i._v(" "),t("li",[i._v("此偏移量表示 要处理原点周围哪些输入")]),i._v(" "),t("li",[i._v("由于每个偏移量都是独立预测的")]),i._v(" "),t("li",[i._v("它们之间无需形成任何刚需形状")]),i._v(" "),t("li",[i._v("第二分支是卷积分支，其输入是这些偏移量处的值")])]),i._v(" "),t("h3",{attrs:{id:"总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[i._v("#")]),i._v(" 总结")]),i._v(" "),t("ol",[t("li",[i._v("CNN层有多种变体。可单独使用也可结合使用。已创建成功且复杂的体系结构，每个变化都是基于特征提取应如何工作的直觉产生的")]),i._v(" "),t("li",[i._v("因此，尽管这些深层CNN网络学到了我们无法解释的权重。但是相信它们的直觉对于它们的性能非常重要，朝着这个方向进行进一步的研究工作对于高度复杂的CNN的成功至关重要。")])]),i._v(" "),t("p",[i._v("​")])])])])}),[],!1,null,null,null);e.default=v.exports}}]);